#!/usr/bin/env python3
"""Maintenance script for FPL AI Optimizer - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏£‡∏∞‡∏ö‡∏ö"""

import os
import sys
import shutil
import gzip
from pathlib import Path
from datetime import datetime, timedelta
import argparse
import subprocess

# Add src to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def clean_logs(days_to_keep=7):
    """Clean old log files."""
    print(f"üßπ ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏•‡πá‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πà‡∏≤‡∏Å‡∏ß‡πà‡∏≤ {days_to_keep} ‡∏ß‡∏±‡∏ô...")
    
    logs_dir = project_root / "logs"
    if not logs_dir.exists():
        print("üìÅ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå logs")
        return
    
    cutoff_date = datetime.now() - timedelta(days=days_to_keep)
    cleaned_files = 0
    
    for log_file in logs_dir.glob("*.log"):
        if log_file.stat().st_mtime < cutoff_date.timestamp():
            try:
                log_file.unlink()
                cleaned_files += 1
                print(f"  ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå: {log_file.name}")
            except Exception as e:
                print(f"  ‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö {log_file.name}: {e}")
    
    # Clean old compressed logs
    for gz_file in logs_dir.glob("*.log.gz"):
        if gz_file.stat().st_mtime < cutoff_date.timestamp():
            try:
                gz_file.unlink()
                cleaned_files += 1
                print(f"  ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå: {gz_file.name}")
            except Exception as e:
                print(f"  ‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö {gz_file.name}: {e}")
    
    print(f"‚úÖ ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô - ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå {cleaned_files} ‡πÑ‡∏ü‡∏•‡πå")


def compress_logs():
    """Compress large log files."""
    print("üì¶ ‡∏ö‡∏µ‡∏ö‡∏≠‡∏±‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏•‡πá‡∏≠‡∏Å‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà...")
    
    logs_dir = project_root / "logs"
    if not logs_dir.exists():
        print("üìÅ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå logs")
        return
    
    max_size_mb = 10  # ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏´‡∏ç‡πà‡∏Å‡∏ß‡πà‡∏≤ 10MB ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏ö‡∏µ‡∏ö‡∏≠‡∏±‡∏î
    compressed_files = 0
    
    for log_file in logs_dir.glob("*.log"):
        size_mb = log_file.stat().st_size / (1024 * 1024)
        
        if size_mb > max_size_mb:
            compressed_path = log_file.with_suffix(log_file.suffix + ".gz")
            
            try:
                with open(log_file, 'rb') as f_in:
                    with gzip.open(compressed_path, 'wb') as f_out:
                        shutil.copyfileobj(f_in, f_out)
                
                # Remove original file
                log_file.unlink()
                compressed_files += 1
                print(f"  ‡∏ö‡∏µ‡∏ö‡∏≠‡∏±‡∏î: {log_file.name} ({size_mb:.1f}MB)")
                
            except Exception as e:
                print(f"  ‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ö‡∏µ‡∏ö‡∏≠‡∏±‡∏î {log_file.name}: {e}")
    
    print(f"‚úÖ ‡∏ö‡∏µ‡∏ö‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô - ‡∏ö‡∏µ‡∏ö‡∏≠‡∏±‡∏î {compressed_files} ‡πÑ‡∏ü‡∏•‡πå")


def vacuum_database():
    """Vacuum SQLite database to reclaim space."""
    print("üóÑÔ∏è  ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (VACUUM)...")
    
    try:
        from src import create_app
        from src.models.db_models import db
        
        app = create_app('development')
        with app.app_context():
            # Get database size before
            db_file = project_root / "data" / "fpl.db"
            if db_file.exists():
                size_before = db_file.stat().st_size / (1024 * 1024)
                print(f"  ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô: {size_before:.2f}MB")
                
                # Run VACUUM
                with db.engine.connect() as conn:
                    conn.execute(db.text("VACUUM"))
                    conn.commit()
                
                # Get size after
                size_after = db_file.stat().st_size / (1024 * 1024)
                saved = size_before - size_after
                print(f"  ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á: {size_after:.2f}MB")
                print(f"  ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà: {saved:.2f}MB")
                
                print("‚úÖ ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
            else:
                print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
                
    except Exception as e:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ: {e}")


def clean_cache():
    """Clear application cache."""
    print("üîÑ ‡∏•‡πâ‡∏≤‡∏á‡πÅ‡∏Ñ‡∏ä...")
    
    try:
        from src import create_app
        
        app = create_app('development')
        with app.app_context():
            # Clear Redis cache if available
            try:
                import redis
                r = redis.Redis(host='localhost', port=6379, db=0)
                r.flushdb()
                print("‚úÖ ‡∏•‡πâ‡∏≤‡∏á Redis cache ‡πÅ‡∏•‡πâ‡∏ß")
            except:
                print("‚ÑπÔ∏è  Redis ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
            
            # Clear file-based cache if exists
            cache_dir = project_root / "cache"
            if cache_dir.exists():
                shutil.rmtree(cache_dir)
                print("‚úÖ ‡∏•‡πâ‡∏≤‡∏á File cache ‡πÅ‡∏•‡πâ‡∏ß")
            
            print("‚úÖ ‡∏•‡πâ‡∏≤‡∏á‡πÅ‡∏Ñ‡∏ä‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
            
    except Exception as e:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡πâ‡∏≤‡∏á‡πÅ‡∏Ñ‡∏ä‡πÑ‡∏î‡πâ: {e}")


def backup_database():
    """Create database backup."""
    print("üíæ ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
    
    db_file = project_root / "data" / "fpl.db"
    if not db_file.exists():
        print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        return
    
    # Create backups directory
    backups_dir = project_root / "backups"
    backups_dir.mkdir(exist_ok=True)
    
    # Create backup filename with timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_file = backups_dir / f"fpl_backup_{timestamp}.db"
    
    try:
        shutil.copy2(db_file, backup_file)
        
        # Compress backup
        with open(backup_file, 'rb') as f_in:
            with gzip.open(f"{backup_file}.gz", 'wb') as f_out:
                shutil.copyfileobj(f_in, f_out)
        
        # Remove uncompressed backup
        backup_file.unlink()
        
        size_mb = Path(f"{backup_file}.gz").stat().st_size / (1024 * 1024)
        print(f"‚úÖ ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô: {backup_file.name}.gz ({size_mb:.2f}MB)")
        
        # Clean old backups (keep last 10)
        backups = sorted(backups_dir.glob("fpl_backup_*.db.gz"), reverse=True)
        for old_backup in backups[10:]:
            old_backup.unlink()
            print(f"  ‡∏•‡∏ö‡∏™‡∏≥‡∏£‡∏≠‡∏á‡πÄ‡∏Å‡πà‡∏≤: {old_backup.name}")
            
    except Exception as e:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ: {e}")


def update_data():
    """Update FPL data and retrain models."""
    print("üîÑ ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• FPL...")
    
    try:
        # Fetch latest FPL data
        result = subprocess.run([
            sys.executable, "scripts/fetch_fpl_data.py"
        ], capture_output=True, text=True, cwd=project_root)
        
        if result.returncode == 0:
            print("‚úÖ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            
            # Retrain models
            print("ü§ñ ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• ML ‡πÉ‡∏´‡∏°‡πà...")
            result = subprocess.run([
                sys.executable, "scripts/train_models.py"
            ], capture_output=True, text=True, cwd=project_root)
            
            if result.returncode == 0:
                print("‚úÖ ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            else:
                print(f"‚ùå ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {result.stderr}")
        else:
            print(f"‚ùå ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {result.stderr}")
            
    except Exception as e:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ: {e}")


def check_disk_space():
    """Check available disk space."""
    print("üíæ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏™‡∏Å‡πå...")
    
    try:
        total, used, free = shutil.disk_usage(project_root)
        
        total_gb = total / (1024**3)
        used_gb = used / (1024**3)
        free_gb = free / (1024**3)
        
        print(f"  ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_gb:.1f}GB")
        print(f"  ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ: {used_gb:.1f}GB")
        print(f"  ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ß‡πà‡∏≤‡∏á: {free_gb:.1f}GB")
        
        if free_gb < 1.0:  # Less than 1GB free
            print("‚ö†Ô∏è  ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡πâ‡∏≠‡∏¢ - ‡∏Ñ‡∏ß‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î")
            return False
        else:
            print("‚úÖ ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏™‡∏Å‡πå‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠")
            return True
            
    except Exception as e:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏™‡∏Å‡πå‡πÑ‡∏î‡πâ: {e}")
        return None


def system_health_check():
    """Perform system health check."""
    print("üè• ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏£‡∏∞‡∏ö‡∏ö...")
    
    health_status = {
        "database": False,
        "ml_models": False,
        "disk_space": False,
        "api_connectivity": False
    }
    
    # Check database
    try:
        from src import create_app
        from src.models.db_models import db
        
        app = create_app('development')
        with app.app_context():
            with db.engine.connect() as conn:
                conn.execute(db.text('SELECT COUNT(*) FROM players'))
            health_status["database"] = True
            print("  ‚úÖ ‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: ‡∏õ‡∏Å‡∏ï‡∏¥")
    except:
        print("  ‚ùå ‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: ‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤")
    
    # Check ML models
    models_dir = project_root / "models"
    if models_dir.exists() and list(models_dir.glob("*.pkl")):
        health_status["ml_models"] = True
        print("  ‚úÖ ‡πÇ‡∏°‡πÄ‡∏î‡∏• ML: ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
    else:
        print("  ‚ùå ‡πÇ‡∏°‡πÄ‡∏î‡∏• ML: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•")
    
    # Check disk space
    disk_ok = check_disk_space()
    if disk_ok:
        health_status["disk_space"] = True
    
    # Check API connectivity
    try:
        import requests
        response = requests.get(
            "https://fantasy.premierleague.com/api/bootstrap-static/",
            timeout=10
        )
        if response.status_code == 200:
            health_status["api_connectivity"] = True
            print("  ‚úÖ FPL API: ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ")
        else:
            print(f"  ‚ùå FPL API: ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ {response.status_code}")
    except:
        print("  ‚ùå FPL API: ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ")
    
    # Summary
    healthy_components = sum(health_status.values())
    total_components = len(health_status)
    
    print(f"\nüìä ‡∏™‡∏£‡∏∏‡∏õ: {healthy_components}/{total_components} ‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏õ‡∏Å‡∏ï‡∏¥")
    
    if healthy_components == total_components:
        print("üéâ ‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏õ‡∏Å‡∏ï‡∏¥‡∏ó‡∏∏‡∏Å‡∏™‡πà‡∏ß‡∏ô!")
    elif healthy_components >= total_components * 0.75:
        print("‚ö†Ô∏è  ‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏õ‡∏Å‡∏ï‡∏¥ ‡πÅ‡∏ï‡πà‡∏°‡∏µ‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç")
    else:
        print("üö® ‡∏£‡∏∞‡∏ö‡∏ö‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏´‡∏•‡∏≤‡∏¢‡∏™‡πà‡∏ß‡∏ô ‡∏Ñ‡∏ß‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç")
    
    return health_status


def generate_maintenance_report():
    """Generate maintenance report."""
    print("üìÑ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏£‡∏±‡∏Å‡∏©‡∏≤...")
    
    report = {
        "timestamp": datetime.now().isoformat(),
        "maintenance_performed": [],
        "system_health": {},
        "recommendations": []
    }
    
    # Run health check
    health = system_health_check()
    report["system_health"] = health
    
    # Generate recommendations
    if not health.get("database", False):
        report["recommendations"].append("‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà: python scripts/setup_database.py")
    
    if not health.get("ml_models", False):
        report["recommendations"].append("‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• ML: python scripts/train_models.py")
    
    if not health.get("api_connectivity", False):
        report["recommendations"].append("‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï")
    
    # Save report
    try:
        report_file = project_root / "maintenance_report.json"
        import json
        with open(report_file, "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        print(f"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô: {report_file}")
    except Exception as e:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ: {e}")
    
    return report


def main():
    """Main maintenance function."""
    parser = argparse.ArgumentParser(description="FPL AI Optimizer Maintenance Script")
    parser.add_argument("--clean-logs", action="store_true", help="Clean old log files")
    parser.add_argument("--compress-logs", action="store_true", help="Compress large log files")
    parser.add_argument("--vacuum-db", action="store_true", help="Vacuum database")
    parser.add_argument("--clear-cache", action="store_true", help="Clear application cache")
    parser.add_argument("--backup-db", action="store_true", help="Backup database")
    parser.add_argument("--update-data", action="store_true", help="Update FPL data and retrain models")
    parser.add_argument("--health-check", action="store_true", help="Perform system health check")
    parser.add_argument("--full-maintenance", action="store_true", help="Perform full maintenance")
    parser.add_argument("--days-to-keep", type=int, default=7, help="Days of logs to keep (default: 7)")
    
    args = parser.parse_args()
    
    if not any(vars(args).values()) or args.health_check:
        # Default: just health check
        system_health_check()
        return
    
    print("üîß FPL AI Optimizer - Maintenance Script")
    print("=" * 50)
    print(f"‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 50)
    
    if args.full_maintenance or args.clean_logs:
        clean_logs(args.days_to_keep)
    
    if args.full_maintenance or args.compress_logs:
        compress_logs()
    
    if args.full_maintenance or args.backup_db:
        backup_database()
    
    if args.full_maintenance or args.vacuum_db:
        vacuum_database()
    
    if args.full_maintenance or args.clear_cache:
        clean_cache()
    
    if args.update_data:
        update_data()
    
    # Always do health check at the end
    print("\n" + "=" * 50)
    final_health = system_health_check()
    
    print("\n" + "=" * 50)
    print("üèÅ ‡∏Å‡∏≤‡∏£‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
    print(f"‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 50)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  ‡∏Å‡∏≤‡∏£‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏ñ‡∏π‡∏Å‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å")
    except Exception as e:
        print(f"\nüö® ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏£‡∏±‡∏Å‡∏©‡∏≤: {e}")
        import traceback
        traceback.print_exc()